# -*- coding: utf-8 -*-
"""mlassignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LICcUQPDKvZ5qkXxMZ4Hfn7QgOpqPLHu
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error

df=pd.read_csv('https://raw.githubusercontent.com/Navya0019/data/main/Salary_dataset11.csv')

df.head()

df.drop(columns=['Age','Gender','Education Level','Job Title'], inplace=True)

df.head()

#plotting the dataset

plt.figure(figsize=(10, 6))

sns.regplot(data=df,
               x='Years of Experience',
               y='Salary',
               marker='*')

#Extracting features and target variables

X = np.array(df['Years of Experience']).reshape(-1,1)
y = np.array(df['Salary']).reshape(-1,1)

# Splitting the dataset into train and test data

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#missing values are filled using imputers


# Instantiate the imputer with the mean strategy
imputer = SimpleImputer(strategy='mean')

# Fit the imputer to the training data and transform it
X_train_imputed = imputer.fit_transform(X_train)
# Impute missing values in y_train
y_train_imputed = imputer.fit_transform(y_train.reshape(-1, 1)).ravel()

# Now you can use X_train_imputed and y_train_imputed for training your linear regression model
linear_reg = LinearRegression()
linear_reg.fit(X_train_imputed, y_train_imputed)

#visualizing the fitted regression line along with the actual data points

plt.scatter(X_train_imputed, y_train_imputed, color='blue', label='Training Data')
plt.plot(X_train_imputed, linear_reg.predict(X_train_imputed), color='red', label='Fitted Line')
plt.xlabel('X')
plt.ylabel('y')
plt.title('Linear Regression Model')
plt.legend()
plt.show()

# Make predictions on the test set using the linear regression model

# Transform the test data using the same imputer to give value for missing values
X_test_imputed = imputer.transform(X_test)
y_test_imputed = imputer.transform(y_test)
# make predictions on X_test_imputed
y_pred = linear_reg.predict(X_test_imputed)

#Evaluating performance/ Evaluating the fit

from sklearn.metrics import r2_score

# Calculate R-squared (coefficient of determination)
r_squared = r2_score(y_test_imputed, y_pred)
print("R-squared (coefficient of determination)/performance score:", r_squared)

#The coefficients represent the slope of the regression line for each feature.
# to understand relationship between  dependent and independent variable

coefficients = linear_reg.coef_
intercept = linear_reg.intercept_
print("Slope:", coefficients[0])
print("Intercept:", intercept)

# Visualize model performance on test data
plt.scatter(X_test, y_test_imputed, color='green', label='Testing Data')
plt.scatter(X_test, y_pred, color='blue', label='Predicted data')
plt.plot(X_test, y_pred, color='red', label='Predicted Line')
plt.xlabel('Years of Experience')
plt.ylabel('Salary')
plt.title('Model Performance on Test Data')
plt.legend()
plt.show()

# Assuming X_new contains new features for prediction

X_new = float(input("Enter the years of Experience : "))

# Reshape X_new to a 2D array predict accepts 2D only
X_new_reshaped = np.array(X_new).reshape(-1, 1)


y_new_pred = linear_reg.predict(X_new_reshaped)
print("Expected Salary is : ",y_new_pred)



